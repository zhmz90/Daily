# Daily

:exclamation: **LESS IS MORE** :exclamation: ** DILIGENCE ** :exclamation:

## month 1 / 2015

### 1/27
- hight level wrapper of bam read, write and query

### 1/26
- bam read and bam write

### 1/25
- bam read formal form
- paper about tumor evolution
- DL of Google

### 1/24
- L1,L2,L3 of DL course from Google

### 1/23
- Deep Learning from Google

### 1/22
- make read bam true

### 1/21
- SeqErrorDetector draft

### 1/20
- HTSLIB.jl

### 1/19
- looking for extreme sparse models in ICML NIPS ICCV and other top journals

### 1/18
- vcf data mining

### 1/17
- assign 1
- week summary

### 1/16
- lecture 3

### 1/15
- check models

### 1/14
- hand compare mutations between Small intestine and Biliary tract

### 1/13
- predict

### 1/12
- model vcf part finish

### 1/11
- fix codes about work
- lecture 2 of cs341n
- check basset

### 1/10
- a good materal: cs341n:Convolutional Neural Networks for Visual Recognition

### 1/9
- Finish work not done of this week
- Apply Deep Learning to kaggle tasks

### 1/8
- report
- MXNet.jl
- apply MXNet.jl

### 1/7 
- rewrite Fusion dectect codes
- use all the haplox data

### 1/6
	find the methods of handle false positive

### 1/5
	finish the model part 

### 1/4
	finish Strict except a good model

### 1/3
	hackerrank python
### 1/2
	9:30-11:00 readdoc,julia
	11:30-2:00 hackerrank python
	2:00-5:30 apply tensorflow to  one kaggle dataset
	5:00-7:00 spark,scala
	8:00-22:00 lan,network,htslib
    readdoc and intro to network, hackerrank, julia, lan
	one or two machine learning or deep learning package 
	spark, scala
### 1/1
	learn Readdoc and hackrank
	learn introduction to network of stanford
## month 12 / 2015
### 12/31
	just remains a few bugs of work. Go to Deep for now.

### 12/30
	focues the classification task.

### 12/29
	make GeneMisc ready for users and prepared to regeister

### PLAN of This Week
	test my model in real cfDNA data

### 12/25
	finish and test gene_location and gene synonym

### 12/24
	Summary about my skills:
		One, mathematics including machine learning, mathematical optimization, PGM.
		Two, computer science including DSA, GPU computing, compiler.

### 12/3
    Flash extended and Alogorithms_stanford urgent

### 12/2
    finish Flash Project

## month 11 / 2015

### 11/27 
    too much ideas to execute so that achived nothing
    First, classification with an emphase on feature selection
    Second, GP tune hyperpara
    Third, PGM / DBM

### 11/4
    1. Learn the structure of COSMIC by PGM
    2. feature selection with random search
### 11/3
    A great idea come in mind.
    chose hyperparameter and do feature selection with Guassian Process
	
## month 10 / 2015
    
### 10/27

    summary current published work on cancer risk prediction


Plan daily since 10/26/2015
